<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <title>spam_filter_ML - xiaosiyier&#39;s blog</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/tomorrow-night-blue.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>xiaosiyier</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                Links
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-06-15 20:32">
      June 15, 2020 pm
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.8k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      47
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>人工智能导论的作业。概述了朴素贝叶斯、支持向量机、N元语法模型三种算法在垃圾邮件过滤问题中的应用。</p>
<a id="more"></a>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><p><a href="#1">1实验目的及文本处理 </a></p>
<ul>
<li><p><a href="#1.0">1.0实验目的 </a></p>
</li>
<li><p><a href="#1.1">1.1文本特征提取：建立词袋 </a> </p>
</li>
</ul>
</li>
<li><p><a href="#2">2朴素贝叶斯</a></p>
</li>
<li><p><a href="#3">3支持向量机</a></p>
</li>
<li><p><a href="#4">4 N元语法模型</a></p>
</li>
<li><p><a href="#2333">参考文献 </a></p>
</li>
</ul>
<h1 id="1">
    1实验目的及文本处理
</h1>


<h2 id="1.0">1.0实验目的</h2>

<p>通过机器学习算法训练模型“垃圾邮件分类器”，实现输入邮件文本，输出邮件分类（垃圾邮件/非垃圾邮件）。</p>
<h2 id="1.1">
    1.1文本特征提取：建立词袋（bag of words）
</h2>


<h3 id="文本预处理："><a href="#文本预处理：" class="headerlink" title="文本预处理："></a>文本预处理：</h3><p>删除频繁出现的无实意词汇：the/and/of…</p>
<p>词形还原：stops/stopped/stopping->stop</p>
<p>若为中文文本，采用jieba分词工具</p>
<p>对过长的邮件内容进行截取，比如只取前3000个字符。</p>
<h3 id="建立词典及特征提取"><a href="#建立词典及特征提取" class="headerlink" title="建立词典及特征提取"></a>建立词典及特征提取</h3><p>建立词频向量。行表示文件，列表示词语，矩阵中第i行第j列的值表示第i个文件中单词j出现的次数。对每一个出现的词，如果不曾被纳入词典，就加入词典，并计数1，如果已存在，就给该项加一。</p>
<h1 id="2">
    2朴素贝叶斯(Naive Bayes)
</h1>


<h2 id="2-0-算法原理"><a href="#2-0-算法原理" class="headerlink" title="2.0 算法原理"></a>2.0 算法原理</h2><p>根据条件概率的贝叶斯公式，有：</p>
<script type="math/tex; mode=display">
P\left( y \middle| x_{1},\ldots,x_{n} \right) = \frac{P\left( y \right)P\left( x_{1},\ldots,x_{n} \middle| y \right)}{P\left( x_{1},\ldots,x_{n} \right)}</script><p>根据朴素贝叶斯的独立性假设，有：</p>
<script type="math/tex; mode=display">
P\left( x_{i} \middle| y,x_{1},\ldots,x_{i - 1},x_{i + 1},\ldots,x_{n} \right) = P\left( x_{i} \middle| y \right)</script><p>综合上述两式，得到：</p>
<script type="math/tex; mode=display">
P\left( y \middle| x_{1},\ldots,x_{n} \right) = \frac{P\left( y \right)\Pi_{i = 1}^{n}P\left( x_{i} \middle| y \right)}{P\left( x_{1},\ldots,x_{n} \right)}</script><p>由于<script type="math/tex">P\left( x_{1},\ldots,x_{n} \right)</script>是一个固定的常值，分类器判断出的类别：</p>
<script type="math/tex; mode=display">
y = argmaxP\left( y \right)\Pi_{i = 1}^{n}P\left( x_{i} \middle| y \right)</script><h2 id="2-1-算法描述"><a href="#2-1-算法描述" class="headerlink" title="2.1 算法描述"></a>2.1 算法描述</h2><ol>
<li><p>数据准备：收集数据（此处指收集若干篇垃圾邮件和正常邮件的文本文件），下载用于学习的数据集。数据集中每一行代表一封邮件。以spam开头代表是垃圾邮件，以ham开头代表是正常邮件。</p>
</li>
<li><p>数据处理（处理数据/清洗数据）：将正常邮件和垃圾邮件的文本文件解析成词条向量。</p>
</li>
<li><p>分析数据：检查词条确保解析的正确性。</p>
</li>
<li><p>训练算法：计算不同的独立特征的条件概率，即</p>
</li>
</ol>
<p>首先计算先验概率，即通过遍历统计每个单词在整个训练集中出现的总次数，算出总频率，再分别统计这个单词在正常邮件、垃圾邮件中出现的频率。</p>
<p>利用朴素贝叶斯的统计学原理的计算公式计算P(wi|c0),<br>P(wi|c1),其中c0代表正常邮件，c1代表垃圾邮件</p>
<ol>
<li><p>测试模型：用测试数据集评估模型预测的正确率，若正确率太低，检查思路，程序，观察并解决出现的问题。</p>
</li>
<li><p>应用算法：构建一个完整的程序对一组未知属性的文本文件进行分类，即对未知分类的一封邮件进行判断，判别其是否为垃圾邮件。</p>
</li>
</ol>
<h2 id="2-2-算法分析"><a href="#2-2-算法分析" class="headerlink" title="2.2 算法分析"></a>2.2 算法分析</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>朴素贝叶斯算法作为一种很传统的机器学习算法，计算速度较快，分类效果较好。下面对朴素贝叶斯算法的优越性进行分析。</p>
<p>首先，现实分类处理的对象常常很切合朴素贝叶斯算法的假设，即针对特定的分类，其各个特征是相互独立的。对于本课题而言，即是垃圾邮件中各个词汇之间相互独立，关联性不强，不会影响彼此的概率分布。</p>
<p>第二，当各个特征之间关联性很强时，有学者研究发现，朴素贝叶斯算法的准确率并没有降低。学者认为，这是归功于朴素贝叶斯算法的“0-1损失函数”的定义。不同于其它很多算法，朴素贝叶斯在训练模型时，并不将分类概率与实际概率的差距作为分类标准，而只惩罚那些分类错误的情况。比如实际上p(+|E)=0.9,<br>p(-|E)=0.1，通过朴素贝叶斯分类器判断出来p’(+|E)=0.6,<br>p’(-|E)=0.4，这时分类器与实际分类的概率相差较大，但分类结果没有出入，因此不对模型进行惩罚。</p>
<h1 id="3">
    3支持向量机(Support Vector Machines)
</h1>


<h2 id="3-0-算法原理"><a href="#3-0-算法原理" class="headerlink" title="3.0 算法原理"></a>3.0 算法原理</h2><h3 id="线性可分支持向量机"><a href="#线性可分支持向量机" class="headerlink" title="线性可分支持向量机"></a>线性可分支持向量机</h3><p>如果训练数据集是线性可分的，我们的目的就是在特征空间中找到一个分离超平面，将实例分为两类（+|-）。这样的分离超平面是有无穷多个的，而利用间隔最大化求最优分离超平面，得到的解是唯一的。算法导出过程如下：</p>
<p>对于给定的训练数据集<script type="math/tex">T = \{\left( x_{1},y_{1} \right),\left( x_{2},y_{2}
\right),\ldots,\left( x_{N},y_{N} \right)\},x_{i} \in R^{n},y_{i} \in \{ + 1. -
1\},i = 1,2,\ldots N</script>，确定超平面<script type="math/tex">w \cdot x + b = 0</script>,记为<script type="math/tex">\left( w,b
\right)</script>，定义超平面关于样本点<script type="math/tex">\left( x_{i},y_{i} \right)</script>的几何间隔为</p>
<script type="math/tex; mode=display">
\gamma_{i} = y_{i}\left( \frac{w}{\left| \left| w \right| \right|} \cdot x_{i} + \frac{b}{\left| \left| w \right| \right|} \right)</script><p>其中<script type="math/tex">y_{i}</script>与后面一项乘积的正负可以体现分类的正确性，而绝对值的大小体现分类的确信度。定义训练集与超平面的几何间隔为</p>
<script type="math/tex; mode=display">
\gamma = min_{i = 1,\ldots,N}\gamma_{i}</script><p>我们需要求解最大间隔分离超平面，可以表示为如下的约束最优化问题：</p>
<script type="math/tex; mode=display">
\text{ma}x_{w,b}\text{\ \ γ}</script><script type="math/tex; mode=display">
\text{s.t.}y_{i}\left( \frac{w}{\left| \left| w \right| \right|} \cdot x_{i} + \frac{b}{\left| \left| w \right| \right|} \right) \geq \gamma,i = 1,2,\ldots,N</script><p>该问题等价于求解</p>
<script type="math/tex; mode=display">
\text{ma}x_{\text{w.b}}\frac{\gamma}{\left| \left| w \right| \right|}</script><script type="math/tex; mode=display">
\text{s.t.}y_{i}\left( w \cdot x_{i} + b \right) \geq \gamma,i = 1,2,\ldots,N</script><p>取<script type="math/tex">\gamma = 1</script>，又注意到<script type="math/tex">\max\frac{1}{\left| \left| w \right|
\right|}\min\frac{1}{2}\left| \left| w \right|
\right|^{2}</script>（此处转化是由于后式便于求导，且导数含<script type="math/tex">w</script>便于计算），所求问题转化为</p>
<script type="math/tex; mode=display">
\text{mi}n_{w,b}\frac{1}{2}\left| \left| w \right| \right|^{2}</script><script type="math/tex; mode=display">
\text{s.t.}y_{i}\left( w \cdot x_{i} + b \right) - 1 \geq 0,i = 1,2,\ldots,N</script><p>由此取得最优解<script type="math/tex">w^{*},b^{*}</script>，得到的分离超平面为</p>
<script type="math/tex; mode=display">
w^{*} \cdot x + b^{*} = 0</script><p>分类决策函数</p>
<script type="math/tex; mode=display">
f\left( x \right) = sign\left( w^{*} \cdot x + b^{*} \right)</script><p><img src="https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=4122790217,405279139&amp;fm=26&amp;gp=0.jpg" srcset="/img/loading.gif" alt="SVMs"></p>
<h3 id="非线性分类"><a href="#非线性分类" class="headerlink" title="非线性分类"></a>非线性分类</h3><p>对于非线性分类问题，可以将其转化为高维空间里的线性分类问题，在线性支持向量机学习的对偶问题里，目标函数和分类决策函数都只涉及实例与实例之间的内积，可以用核函数<br>(kernel<br>function)来进行替换。比如我们需要把针对二维平面的点建立映射，核函数的定义为<script type="math/tex">K\left(
x,y \right) = < f\left( x \right),f\left( y \right) ></script>。一般计算<script type="math/tex">< f\left( x
\right),f\left( y \right) ></script>我们需要先计算出<script type="math/tex">f\left( x \right),f\left( y
\right)</script>，然后再计算点积，这将涉及到很大的计算量。而应用核函数，可以直接建立</p>
<script type="math/tex; mode=display">x,y\$$到$$< f\left( x \right),f\left( y \right) >$$的映射。

例如：定义如下针对三维空间点的映射</script><p>x = \left( x<em>{1},x</em>{2},x_{3} \right),</p>
<script type="math/tex; mode=display">
</script><p>f\left( x \right) = (x<em>{1}x</em>{1},x<em>{1}x</em>{2},x<em>{1}x</em>{3},x<em>{2}x</em>{1},x<em>{2}x</em>{2},x<em>{2}x</em>{3},x<em>{3}x</em>{1},x<em>{3}x</em>{2},x<em>{3}x</em>{3})</p>
<script type="math/tex; mode=display">

用普通方法计算$$< f\left( x \right),f\left( y \right) >$$步骤为：</script><p>x = \left( x<em>{1},x</em>{2},x<em>{3} \right);y = \left( y</em>{1},y<em>{2},y</em>{3} \right);</p>
<script type="math/tex; mode=display">
</script><p>f\left( x \right) = (x<em>{1}x</em>{1},x<em>{1}x</em>{2},x<em>{1}x</em>{3},x<em>{2}x</em>{1},x<em>{2}x</em>{2},x<em>{2}x</em>{3},x<em>{3}x</em>{1},x<em>{3}x</em>{2},x<em>{3}x</em>{3})</p>
<script type="math/tex; mode=display">
</script><p>f\left( y \right) = \left( y<em>{1}y</em>{1},y<em>{1}y</em>{2},y<em>{1}y</em>{3},y<em>{2}y</em>{1},y<em>{2}y</em>{2},y<em>{2}y</em>{3},y<em>{3}y</em>{1},y<em>{3}y</em>{2},y<em>{3}y</em>{3} \right)</p>
<script type="math/tex; mode=display">
</script><p>&lt; f\left( x \right),f\left( y \right) &gt; = \left( x<em>{1}y</em>{1} \right)^{2} + \left( x<em>{2}y</em>{2} \right)^{2} + \left( x<em>{3}y</em>{3} \right)^{2} + 2\left( x<em>{1}x</em>{2}y<em>{1}y</em>{2} + x<em>{1}x</em>{3}y<em>{1}y</em>{3} + x<em>{2}x</em>{3}y<em>{2}y</em>{3} \right)</p>
<script type="math/tex; mode=display">

而通过核函数，我们能够发现：</script><p>\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  &lt; f\left( x \right),f\left( y \right) &gt;</p>
<script type="math/tex; mode=display">
</script><p>= \left( x<em>{1}y</em>{1} + x<em>{2}y</em>{2} + x<em>{3}y</em>{3} \right)^{2} = \left( &lt; x,y &gt; \right)^{2}</p>
<script type="math/tex; mode=display">

这样就避免了多维的复杂计算，降低了算法复杂度。

3.1 算法描述
------------

3.2 算法分析及优化
------------------

线性支持向量机在对一个新的实例进行分类时时间复杂度为$$O\left( s
\right)$$，其中s为非零特征的数量，这个时间复杂度与其它线性分类器是相同的，比如上一个方法朴素贝叶斯。但是训练出一个SVM的时间复杂度为$$O\left(
n^{2} \right)$$，其中n为训练案例数量。

### Online SVM:

在传统的方式中，支持向量机通常采取批处理模式，这是指学习一批固定的训练数据集，然后应用在独立的案例中。而针对邮件分类这种增长式的数据，我们需要对把传统的批处理模式升级为线上处理模式(Online
SVM)，因为邮件是源源不断的，也是需要不断优化的。我们需要让模型在接收每一个案例之后，都会被告知分类正确与否，并对旧的SVM做出调整和更新。

### Relaxed Online SVM(ROSVM)

在训练SVM时，我们需要满足如下条件：

要使下面的函数最小:</script><p>\tau\left( w,\varepsilon \right) = \frac{1}{2}\left| \left| w \right| \right|^{2} + C\sum<em>{i = 1}^{n}\varepsilon</em>{i}</p>
<script type="math/tex; mode=display">

同时满足限制</script><p>for\ all\ i = 1..n:y<em>{i}\left( &lt; w,x</em>{i} &gt; + b \right) \geq 1 - \varepsilon<em>{i},\varepsilon</em>{i} \geq 0</p>
<script type="math/tex; mode=display">

其中$$\varepsilon_{i}$$表示的是对于特定的例子$$x_{i}$$分类器分类错误的数量。使得$$\sum_{i
= 1}^{n}\varepsilon_{i}$$最小等价于使得损失函数最小，而使得$$\left| \left| w
\right|
\right|^{2}$$最小意味着使得两类的距离最大。这两种最优解的寻找通常是冲突的，其中C(
tradeoff
parameter)就反映了对这两种查找的重要性的分配。通过实验，学者发现把C设置为较高的值会得到更高的准确性。把C设置为较高的值意味着达到训练损失最小比实现最大距离要更重要。这就提醒我们，训练过程中注重找到对于所有数据实现最大距离是不必要的，我们就需要对这个需求放宽标准(relax)。有这样几种方式实现放宽标准：

1.  对于该寻找最优问题，将范围限制在最近的p个实例中，而非所有实例。
2.  通过只对错误作出反应，减少对模型更新的次数。
3.  通过允许用近似解取代最优解，减少迭代的次数。

<h1 id="4">
    4 N元语法模型(n-gram language model)
</h1>


4.0 引入
--------

由于现在的垃圾邮件有的会为了躲避词频或特定词的侦查，会选择插入一些特殊符号将词汇变形，而仍然让人能看懂，比如”free”-\>”f\*r\*e\*e”。这种伎俩有时候能欺骗分词工具，使我们提取不到有效词汇。而且对于语法丰富的自然语言，尤其是词形多变的语种，很少有分词工具能够完全将其拆分的。同时，建立词袋只统计词频，而忽视了词出现的顺序，这样会丢失部分信息。

4.1 算法原理
------------

如果我们想要计算$$P\left( w \middle| h
\right)$$，其中w为一个词，h为在它之前的历史文本。那么我们需要一个很大的语料库（比如网络）来统计。比如计算$$P\left(
土豆|我们都爱吃 \right) = \frac{C\left(我们都爱吃土豆
\right)}{C(我们都爱吃)}$$其中C表示（count）次数。但是这种方法从复杂性上、实用性上都不够现实，因此我们需要选择更聪明的方法。

通过链式法则，我们可以将上述概率分解为</script><p>P\left( 我们都爱吃土豆\right) = P\left( 我们\right)P\left( 都\middle| 我们\right)P\left( 爱\middle| 我们都\right)P\left(吃 \middle|我们都爱 \right)P\left(土豆 \middle|我们都爱吃 \right)</p>
<script type="math/tex; mode=display">

定义记号$$w_{a}^{b}$$表示由a到b这b-a+1个词组成的序列，则链式法则用字母表示为</script><p>P\left( w<em>{1}^{n} \right) = P\left( w</em>{1} \right)P\left( w<em>{2} \middle| w</em>{1} \right)P\left( w<em>{3} \middle| w</em>{1}^{2} \right)\ldots P\left( w<em>{n} \middle| w</em>{1}^{n - 1} \right)</p>
<script type="math/tex; mode=display">
</script><p>= \Pi<em>{k = 1}^{n}P\left( w</em>{k} \middle| w_{1}^{k - 1} \right)</p>
<script type="math/tex; mode=display">

N-gram模型的逻辑在于，我们可以用最后几个单词来估计历史h，而不需要查看整个历史中的概率。方程为</script><p>P\left( w<em>{n} \middle| w</em>{1}^{n - 1} \right) \approx P\left( w<em>{n} \middle| w</em>{n - N + 1}^{n - 1} \right)</p>
<script type="math/tex; mode=display">

如果引入马尔科夫假设，即单词的概率只取决于前一个词，那么N-gram特定为bigram(N=2)。可以将联合概率写作</script><p>P\left( w<em>{1}^{n} \right) = \prod</em>{k = 1}^{n}{P\left( w<em>{k} \middle| w</em>{k - 1} \right)}</p>
<p>$$</p>
<h2 id="4-2-实现思路"><a href="#4-2-实现思路" class="headerlink" title="4.2 实现思路"></a>4.2 实现思路</h2><p>采用训练集，分别训练出两个分类spam/ham的模型。对于新的测试邮件，分别通过两个模型得到的概率去预测它，看哪个模型预测得更接近，就将其归为哪一类。此过程可以衍生出很多方法，比如分词方式有词组、字符等，判断方式也可以只依靠邮件的前几个词。</p>
<p>有人采用了字符为单位的学习方式。这表示对文本进行划分的单元不是单词，而是几个字符，比如将discount分为3个字母一组，这样就算被插入了一些扰乱的字符，比如di<em>scount，在这种分词模式下分成di</em>|sco|oun|t，与discount的大部分小模块还是相同的。</p>
<h2 id="4-3算法分析"><a href="#4-3算法分析" class="headerlink" title="4.3算法分析"></a>4.3算法分析</h2><h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><p>包含了前N-1个词能提供的全部信息，并且原理简单容易实现。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>首先，这种方法需要大量的训练数据来确定模型的参数。</p>
<p>还有，因为数据稀疏会导致出现数据平滑问题。比如很多词汇组合的概率为0，这时就需要优化算法。</p>
<h2 id="2333">
    参考文献
</h2>


<ol>
<li><p>Naïve Bayes: <a href="https://scikit-learn.org/stable/modules/naive_bayes.html" target="_blank" rel="noopener">https://scikit-learn.org/stable/modules/naive_bayes.html</a></p>
</li>
<li><p>SVM：《统计学习方法》，李航 著。</p>
</li>
<li><p>”Relaxed Online SVMs for Spam Filtering”:<br><a href="https://www.eecs.tufts.edu/~dsculley/papers/emailAndWebSpamSIGIR.pdf" target="_blank" rel="noopener">https://www.eecs.tufts.edu/~dsculley/papers/emailAndWebSpamSIGIR.pdf</a></p>
</li>
<li><p>n元语法模型：&lt;<a href="https://web.stanford.edu/~juraf" target="_blank" rel="noopener">https://web.stanford.edu/~juraf</a></p>
</li>
</ol>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Machine-Learning/">Machine Learning</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/06/15/hello-world/">
                        <span class="hidden-mobile">Hello World</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      function loadDisqus() {
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2020/06/15/spam-filter-ML/';
          this.page.identifier = '/2020/06/15/spam-filter-ML/';
        };
        (function () {
          var d = document,
            s = d.createElement('script');
          s.src = '//' + '' + '.disqus.com/embed.js';
          s.setAttribute('data-timestamp', new Date());
          (d.head || d.body).appendChild(s);
        })();
      }
      createObserver(loadDisqus, 'disqus_thread');
    </script>
    <noscript>Please enable JavaScript to view the
      <a href="https://disqus.com/?ref_noscript" target="_blank" rel="nofollow noopener noopener">comments powered by Disqus.</a>
    </noscript>
  </div>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "spam_filter_ML&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  
















</body>
</html>
