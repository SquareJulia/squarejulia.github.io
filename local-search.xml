<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>daily update</title>
    <link href="/2021/04/21/daily-update/"/>
    <url>/2021/04/21/daily-update/</url>
    
    <content type="html"><![CDATA[<p>昨天没有学<strong>模电</strong>，今天学了一个小时<strong>模电</strong>，回宿舍洗完澡还要学<strong>模电</strong>，<strong>模电</strong>必不能挂科。今天上午隆重地出席了一堂课，表扬自己。下午抄答案，写一点汇编。好想要么变小要么变老，就不想在此时此地待着。还是做梦。</p><hr><p>今天中午真的想学习来着，但是喝了奶茶太撑了，就溜达了。现在要去西十二上课了。晚上一定要跑15圈！&lt;-跑完了！看到了帅哥，就觉得，把很多段关系就这么留在时光里，有一点不负责任，有一点无奈。本来想学很多科目的，结果只学了计算机系统基础，还没写完作业。现在把作业写了，希望能再看看汇编。听袁娅维的《为你而来》听上瘾了，就那一句旋律和歌词特别抓人：</p><blockquote><p>为你而来</p><p>几辈子都只想和你有关</p></blockquote><p>昨天又做了好多好多梦，离奇且具体，细节多到爆炸。今天没有学<strong>模电</strong>，明天上午一定要学。明天好像没机会运动了，有晚课，烦。明天就穿格子衫吧，平平淡淡。</p><hr><p>昨天做梦梦见帅哥了，太帅了太帅了，还在我面前笑。今天下午睡觉，试图弄汇编win32，但是include一直报错，现在也不知道怎么弄。就先放下吧。晚上创建了n遍工程，可以小心翼翼地一点一点改现成的代码。回宿舍洗了澡必须学<strong>模电</strong>。骑车的时候在想木心那句</p><blockquote><p>念予毕生流离红尘，就找不到一个似粥温柔的人。</p></blockquote><hr><p>今天上午骑车去交实验报告，金老师是很温和的人。去吃了东教工食堂，鸡块虽然有点咸，但还是好吃的。就是断断续续想帅哥。三年前520，好久远好久远，可能我现在气质里还残留着你的温柔吧。越想越不可思议，我们是两个多固执的人啊，怎么就能凑到一起去了呢。下午写了汇编实验，晚上把汇编实验再写一写。然后学一会儿<strong>模电</strong>。晚上只跑了2圈就累了，日子快到了。</p><hr><p>昨晚到今天基本没学习，跑了1600，和好几个人聊天聊好久。写了汇编实验报告。腰疼。斥巨资给朋友买了瑞士莲巧克力，收到巧克力一定会很幸福的呀~然后就是搅扰我睡眠的事情了，520。三年前多潇洒，现在就多悲催。现在想学verilog，不想学<strong>模电</strong>。今天要早睡。想要和爸爸牵手。</p><hr><p>昨天睡了十个多小时，今天一直昏昏沉沉，头疼。删了一个好友，又是很舍不得但不得不斩断的关系。昨天看了一点季羡林的散文，觉得有点过于中庸，不太有进取精神。如果每个人只有一点点超能力，或许赋予了我想象力和勇气，也没再多些脚踏实地的勤奋和知足。东西学不完。现在还是把csapp实验写了吧。今天学了一会儿<strong>模电</strong>。删了的好友也就是那么一种关系吧，好不容易了解、走近，曾借给彼此心里的一片空间，也有幸占据过对方的一片空间，只是为了彼此只能选择疏离。是不是也是渴望建立与周遭的关联的一种体现呢，哪怕是躲避，哪怕是尴尬，也好过全然的冷漠和视而不见。</p><hr><p>今天说着怎么烧不起来，然后就烧起来了，然后体验了救护车-留观流程。可以纵容自己什么也不做，但还是渴望关心 。翻来覆去还是那些人。最思念的人躺在陌生人的名单里。看了一些歌词，一些李宗盛，一些五月天。“爱恋是一场高烧，思念是紧跟着的好不了的咳。”还有朋友一直不回消息，也是莫名其妙。还是怕挂科。本来在病房想攒一首诗的，韵都想好了，突然出结果放人了。看了点知乎，流浪者的爱情寄托在流浪里，有点感觉吧。发烧好像头脑还是很清醒，只是放松下来会头疼头晕。现在想写一点verilog。真希望能很快做完它。有点想c先生了，今天在病房想起他，这点小事还不足以惊动他到把我好友加回来的地步吧，也许只有什么绝症灾难降临，能让他受到什么回忆的召唤，回头瞥一眼我的生活。也可能真到那个地步，我们最好的结局还是不要见到彼此不堪又无力的样子吧。然后就是今天跟陌生人共处一间病房，又一次感觉到人和人的距离。她会关心一下，到黄昏的时候要开个灯，怕我想家了。已经好难得好难得了，但也真的到此为止了。在医院又感觉，说人生不如意十有八九，其实十有八九的时间都是平淡日常的，因为安稳和舒适，所以不察觉到它的存在，只是那些尖刻的不如意格外入眼入心。</p><p>抄一些《好好》的歌词</p><blockquote><p>我们都要把自己照顾好</p><p>好到遗憾无法打扰</p><p>好好的生活</p><p>好好的变老</p><p>好好假装我</p><p>已经把你忘掉</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Life</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>《图解HTTP》学习笔记</title>
    <link href="/2020/07/02/%E3%80%8A%E5%9B%BE%E8%A7%A3HTTP%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/02/%E3%80%8A%E5%9B%BE%E8%A7%A3HTTP%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>本人记这篇笔记的逻辑，就是把部分<em>中文</em>翻译成<em>英文</em>改写一下。</p><a id="more"></a><h1 id="HTTP学习笔记"><a href="#HTTP学习笔记" class="headerlink" title="HTTP学习笔记"></a>HTTP学习笔记</h1><p>简介在<a href="https://www.ituring.com.cn/book/1229" target="_blank" rel="noopener">这里</a>，京东购买链接在<a href="https://item.jd.com/11449491.html" target="_blank" rel="noopener">这里</a>。</p><ul><li><p>WWW构建技术</p><ul><li><p>文本标记语言：HTML</p></li><li><p>文档传递协议：HTTP</p></li><li><p>指定文档所在地址：URL</p><p>URL是URI的子集。URI：由某个协议方案表示的资源的定位标识符。 </p><p>绝对URI格式：协议方案名://(登录信息@)服务器地址:(服务器端口号)带层次的文件路径?(查询字符串)#(片段标识符)</p></li></ul></li><li><p>TCP/IP的分层管理</p><p>发送端每经过一层增加首部，接收端删除首部。</p><ul><li><p>应用层：决定向用户提供应用服务时通信的活动。</p><ul><li><p>FTP: File Transfer Protocol</p></li><li><p>DNS: Domain Name System</p><p>计算机处理IP地址，而人记忆主机名或域名，DNS可双向查找</p></li><li><p>HTTP: HyperText Transfer Protocol</p></li><li><p>…</p></li></ul></li><li><p>传输层：提供处于网络连接中两台计算机之间的数据传输</p><ul><li><p>TCP: Transmission Control Protocol</p><ul><li><p>提供字节流服务(Byte Stream Service)，分割大块数据为以报文段为单位的数据包</p></li><li><p>确认数据是否送达到对方</p><p>采用三次握手（数据包上打标志）：发送端SYN(syncronize)-&gt;接收端SYN/ACK(acknowlegement)-&gt;发送端ACK</p></li></ul></li><li><p>UDP: User Data Protocol</p></li></ul></li><li><p>网络层：选择传输路线，传送数据包。</p><ul><li>IP: Internet Protocol 二者可配对<ul><li>IP地址：节点被分配的地址（可变）</li><li>MAC地址：Media Access Control Address网卡所属固定地址（固定）</li><li>ARP协议(Address Resolution Protocol)：解析地址，根据通信方的IP地址反查出对应的MAC地址</li></ul></li></ul></li><li><p>数据链路层：处理连接网络的硬件部分。</p></li></ul></li></ul><hr><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><p>请求报文：</p><blockquote><p>method request-URI HTTP_version</p><p>(header field)</p><p>CR+LF</p><p>(entity body)</p></blockquote><p>响应报文：</p><blockquote><p>HTTP_version status_code reason-phrase</p><p>(header field)</p><p>CR+LF</p><p>(entity body)</p></blockquote><ul><li><p>stateless(less server burden)</p><ul><li><p>use Cookie to memorize login status</p><p>Server send a <code>Set-Cookie</code> in <code>header field</code>; Client add Cookie in subsequent requests; </p></li></ul></li><li><p>request-URI</p><ul><li>complete format in <code>request-URI</code></li><li>domain name/IP address in <code>header field</code>-&gt;<code>Host:</code></li><li>not intended for specific resource: *</li></ul></li><li><p>method</p><ul><li><p>GET</p></li><li><p>POST</p></li><li><p>PUT: transfer file</p><p>not secure-&gt;if used with REST standard/other verification methods, OK</p></li><li><p>HEAD: similar to GET-&gt;only <code>header field</code></p></li><li><p>DELETE: opposite to PUT</p><p>similar secure requirement</p></li><li><p>OPTIONS: inquire suppor methods of the target URI</p></li><li><p>TRACE: <code>Max-Forwards</code> in <code>header field</code> -&gt; when cut down to 0, server return 200 OK</p><p>often not used. attacked by XST(Cross-Site Tracing)</p></li><li><p>CONNECT: establish tunnel with proxy server</p></li></ul></li><li><p>HTTP Persistent Connections: TCP connect-&gt;HTTP-&gt;HTTP-&gt;…-&gt;HTTP-&gt;TCP disconnect</p><p>enable pipelining: send another request before the former one’s response</p></li><li><p>Encode</p><ul><li><p>内容编码：指明应用在实体内容上的编码格式，保持实体信息原样压缩，客户端接收并负责解码。</p><ul><li><p>gzip(GNU zip)</p></li><li><p>compress(UNIX standard)</p></li><li><p>deflate(zlib)</p></li><li><p>identity</p></li></ul></li><li><p>Chunked Transfer Coding</p></li></ul></li><li><p>Multipart</p><ul><li><p>MIME: Multiple Internet Mail Extensions</p></li><li><p>multipart/form-data</p></li><li><p>multipart/byteranges</p><p>status_code=206 Partial Content</p></li></ul></li><li><p>Range Request(Header field)</p></li><li><p>Content Negotiation : between Client and Server</p><ul><li><p>judge standard:(Header field)</p><ul><li>Accept</li><li>Accept-Charset</li><li>Accept-Encoding</li><li>Accept-Language</li><li>Content-Language</li></ul></li><li><p>Type</p><ul><li>Server-driven Negotiation</li><li>Agent-driven Negotiation : manual/automatic</li><li>Transparent Negotiation</li></ul></li></ul></li></ul><hr><h2 id="Status-code"><a href="#Status-code" class="headerlink" title="Status_code"></a>Status_code</h2><ul><li>1xx Informational</li><li>2xx Success<ul><li>200 OK</li><li>204 No Content : often used when there’s no need for Client to send new messages to Server</li><li>206 Partial Content</li></ul></li><li>3xx Redirection(301-303: change POST into GET and resend request automatically)<ul><li>301 Moved Permanently : new request URI-&gt;change bookmark</li><li>302 Found : new request URI : still flexible</li><li>303 See Other : similar to 302 -&gt; expect Client use GET method</li><li>304 Not Modified : Server allow GET resource, but additional condition not satisfied</li><li>307 Temporary Redirect: similar to 302, but not change POST into GET</li></ul></li><li>4xx Client Error<ul><li>400 Bad Request : grammar error in request</li><li>401 Unauthorized</li><li>403 Forbidden</li><li>404 Not Found</li></ul></li><li>5xx Server Error<ul><li>500 Internal Server Error</li><li>503 Service Unavailable</li></ul></li></ul><hr><h2 id="HTTPS-HTTP-SSL"><a href="#HTTPS-HTTP-SSL" class="headerlink" title="HTTPS(HTTP+SSL)"></a>HTTPS(HTTP+SSL)</h2><p>SSL(Secure Socket Layer)|TLS(Transport Layer Security)</p><ul><li><p>加密</p><p>2共享密钥加密 &amp;&amp; 1公开密钥加密（慢）</p><p>证书：</p><ul><li>证明服务器是否规范</li><li>确认对方服务器背后企业是否存在—EV SSL证书</li><li>客户端认证</li></ul></li></ul><hr><h2 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h2><ul><li><p>BASIC认证（采用Base64编码，不够安全）</p></li><li><p>DIGEST认证（摘要认证）</p><p>challenge—response</p></li><li><p>SSL</p></li><li><p><strong>表单认证</strong></p></li></ul><hr><h2 id="Additional"><a href="#Additional" class="headerlink" title="Additional"></a>Additional</h2><ul><li><p>Ajax(Asynchronous JavaScript and XML) : Update partial content</p><ul><li>XMLHttpRequest(API): use Js to commuticate through HTTP</li></ul></li><li><p>Comet: Server Push</p></li><li><p>SPDY:</p><ul><li>HTTP Persistent Connections</li><li>set priorities for requests(multiple)</li><li>compress HTTP header</li><li>server push</li><li>server hint</li></ul></li><li><p>WebSocket</p><ul><li>server push</li><li>reduce content</li></ul></li><li><p>HTTP Speed + Mobility</p></li></ul><hr><h2 id="攻击"><a href="#攻击" class="headerlink" title="攻击"></a>攻击</h2><ul><li><p>在客户端篡改请求</p><p>SQL注入攻击 OS命令注入攻击</p></li><li><p>主动攻击\被动攻击</p><p>跨站脚本攻击 跨站点请求伪造</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spam_filter_ML</title>
    <link href="/2020/06/15/spam-filter-ML/"/>
    <url>/2020/06/15/spam-filter-ML/</url>
    
    <content type="html"><![CDATA[<p>人工智能导论的作业。概述了朴素贝叶斯、支持向量机、N元语法模型三种算法在垃圾邮件过滤问题中的应用。</p><a id="more"></a><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><p><a href="#1">1实验目的及文本处理 </a></p><ul><li><p><a href="#1.0">1.0实验目的 </a></p></li><li><p><a href="#1.1">1.1文本特征提取：建立词袋 </a> </p></li></ul></li><li><p><a href="#2">2朴素贝叶斯</a></p></li><li><p><a href="#3">3支持向量机</a></p></li><li><p><a href="#4">4N元语法模型</a></p></li><li><p><a href="#2333">参考文献 </a></p></li></ul><h1 id="1">    1实验目的及文本处理</h1><h2 id="1.0">1.0实验目的</h2><p>通过机器学习算法训练模型“垃圾邮件分类器”，实现输入邮件文本，输出邮件分类（垃圾邮件/非垃圾邮件）。</p><h2 id="1.1">    1.1文本特征提取：建立词袋（bag of words）</h2><h3 id="文本预处理："><a href="#文本预处理：" class="headerlink" title="文本预处理："></a>文本预处理：</h3><p>删除频繁出现的无实意词汇：the/and/of…</p><p>词形还原：stops/stopped/stopping->stop</p><p>若为中文文本，采用jieba分词工具</p><p>对过长的邮件内容进行截取，比如只取前3000个字符。</p><h3 id="建立词典及特征提取"><a href="#建立词典及特征提取" class="headerlink" title="建立词典及特征提取"></a>建立词典及特征提取</h3><p>建立词频向量。行表示文件，列表示词语，矩阵中第i行第j列的值表示第i个文件中单词j出现的次数。对每一个出现的词，如果不曾被纳入词典，就加入词典，并计数1，如果已存在，就给该项加一。</p><h1 id="2">    2朴素贝叶斯(Naive Bayes)</h1><h2 id="2-0-算法原理"><a href="#2-0-算法原理" class="headerlink" title="2.0 算法原理"></a>2.0 算法原理</h2><p>根据条件概率的贝叶斯公式，有：</p><script type="math/tex; mode=display">P\left( y \middle| x_{1},\ldots,x_{n} \right) = \frac{P\left( y \right)P\left( x_{1},\ldots,x_{n} \middle| y \right)}{P\left( x_{1},\ldots,x_{n} \right)}</script><p>根据朴素贝叶斯的独立性假设，有：</p><script type="math/tex; mode=display">P\left( x_{i} \middle| y,x_{1},\ldots,x_{i - 1},x_{i + 1},\ldots,x_{n} \right) = P\left( x_{i} \middle| y \right)</script><p>综合上述两式，得到：</p><script type="math/tex; mode=display">P\left( y \middle| x_{1},\ldots,x_{n} \right) = \frac{P\left( y \right)\Pi_{i = 1}^{n}P\left( x_{i} \middle| y \right)}{P\left( x_{1},\ldots,x_{n} \right)}</script><p>由于<script type="math/tex">P\left( x_{1},\ldots,x_{n} \right)</script>是一个固定的常值，分类器判断出的类别：</p><script type="math/tex; mode=display">y = argmaxP\left( y \right)\Pi_{i = 1}^{n}P\left( x_{i} \middle| y \right)</script><h2 id="2-1-算法描述"><a href="#2-1-算法描述" class="headerlink" title="2.1 算法描述"></a>2.1 算法描述</h2><ol><li><p>数据准备：收集数据（此处指收集若干篇垃圾邮件和正常邮件的文本文件），下载用于学习的数据集。数据集中每一行代表一封邮件。以spam开头代表是垃圾邮件，以ham开头代表是正常邮件。</p></li><li><p>数据处理（处理数据/清洗数据）：将正常邮件和垃圾邮件的文本文件解析成词条向量。</p></li><li><p>分析数据：检查词条确保解析的正确性。</p></li><li><p>训练算法：计算不同的独立特征的条件概率，即</p></li></ol><p>首先计算先验概率，即通过遍历统计每个单词在整个训练集中出现的总次数，算出总频率，再分别统计这个单词在正常邮件、垃圾邮件中出现的频率。</p><p>利用朴素贝叶斯的统计学原理的计算公式计算P(wi|c0),<br>P(wi|c1),其中c0代表正常邮件，c1代表垃圾邮件</p><ol><li><p>测试模型：用测试数据集评估模型预测的正确率，若正确率太低，检查思路，程序，观察并解决出现的问题。</p></li><li><p>应用算法：构建一个完整的程序对一组未知属性的文本文件进行分类，即对未知分类的一封邮件进行判断，判别其是否为垃圾邮件。</p></li></ol><h2 id="2-2-算法分析"><a href="#2-2-算法分析" class="headerlink" title="2.2 算法分析"></a>2.2 算法分析</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>朴素贝叶斯算法作为一种很传统的机器学习算法，计算速度较快，分类效果较好。下面对朴素贝叶斯算法的优越性进行分析。</p><p>首先，现实分类处理的对象常常很切合朴素贝叶斯算法的假设，即针对特定的分类，其各个特征是相互独立的。对于本课题而言，即是垃圾邮件中各个词汇之间相互独立，关联性不强，不会影响彼此的概率分布。</p><p>第二，当各个特征之间关联性很强时，有学者研究发现，朴素贝叶斯算法的准确率并没有降低。学者认为，这是归功于朴素贝叶斯算法的“0-1损失函数”的定义。不同于其它很多算法，朴素贝叶斯在训练模型时，并不将分类概率与实际概率的差距作为分类标准，而只惩罚那些分类错误的情况。比如实际上p(+|E)=0.9,<br>p(-|E)=0.1，通过朴素贝叶斯分类器判断出来p’(+|E)=0.6,<br>p’(-|E)=0.4，这时分类器与实际分类的概率相差较大，但分类结果没有出入，因此不对模型进行惩罚。</p><h1 id="3">    3支持向量机(Support Vector Machines)</h1>3.0 算法原理------------### 线性可分支持向量机如果训练数据集是线性可分的，我们的目的就是在特征空间中找到一个分离超平面，将实例分为两类（+\|-）。这样的分离超平面是有无穷多个的，而利用间隔最大化求最优分离超平面，得到的解是唯一的。算法导出过程如下：对于给定的训练数据集$$T = \{\left( x_{1},y_{1} \right),\left( x_{2},y_{2}\right),\ldots,\left( x_{N},y_{N} \right)\},x_{i} \in R^{n},y_{i} \in \{ + 1. -1\},i = 1,2,\ldots N$$，确定超平面$$w \cdot x + b = 0$$,记为$$\left( w,b\right)$$，定义超平面关于样本点$$\left( x_{i},y_{i} \right)$$的几何间隔为$$\gamma_{i} = y_{i}\left( \frac{w}{\left| \left| w \right| \right|} \cdot x_{i} + \frac{b}{\left| \left| w \right| \right|} \right)$$其中$$y_{i}$$与后面一项乘积的正负可以体现分类的正确性，而绝对值的大小体现分类的确信度。定义训练集与超平面的几何间隔为$$\gamma = min_{i = 1,\ldots,N}\gamma_{i}$$我们需要求解最大间隔分离超平面，可以表示为如下的约束最优化问题：$$\text{ma}x_{w,b}\text{\ \ γ}$$$$\text{s.t.}y_{i}\left( \frac{w}{\left| \left| w \right| \right|} \cdot x_{i} + \frac{b}{\left| \left| w \right| \right|} \right) \geq \gamma,i = 1,2,\ldots,N$$该问题等价于求解$$\text{ma}x_{\text{w.b}}\frac{\gamma}{\left| \left| w \right| \right|}$$$$\text{s.t.}y_{i}\left( w \cdot x_{i} + b \right) \geq \gamma,i = 1,2,\ldots,N$$取$$\gamma = 1$$，又注意到$$\max\frac{1}{\left| \left| w \right|\right|}\min\frac{1}{2}\left| \left| w \right|\right|^{2}$$（此处转化是由于后式便于求导，且导数含$$w$$便于计算），所求问题转化为$$\text{mi}n_{w,b}\frac{1}{2}\left| \left| w \right| \right|^{2}$$$$\text{s.t.}y_{i}\left( w \cdot x_{i} + b \right) - 1 \geq 0,i = 1,2,\ldots,N$$由此取得最优解$$w^{*},b^{*}$$，得到的分离超平面为$$w^{*} \cdot x + b^{*} = 0$$分类决策函数$$f\left( x \right) = sign\left( w^{*} \cdot x + b^{*} \right)$$![SVMs](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=4122790217,405279139&fm=26&gp=0.jpg)### 非线性分类对于非线性分类问题，可以将其转化为高维空间里的线性分类问题，在线性支持向量机学习的对偶问题里，目标函数和分类决策函数都只涉及实例与实例之间的内积，可以用核函数(kernelfunction)来进行替换。比如我们需要把针对二维平面的点建立映射，核函数的定义为$$K\left(x,y \right) = < f\left( x \right),f\left( y \right) >$$。一般计算$$< f\left( x\right),f\left( y \right) >$$我们需要先计算出$$f\left( x \right),f\left( y\right)$$，然后再计算点积，这将涉及到很大的计算量。而应用核函数，可以直接建立$$x,y\$$ 到 $$< f\left( x \right),f\left( y \right) >$$ 的映射。例如：定义如下针对三维空间点的映射$$x = \left( x_{1},x_{2},x_{3} \right),$$$$f\left( x \right) = (x_{1}x_{1},x_{1}x_{2},x_{1}x_{3},x_{2}x_{1},x_{2}x_{2},x_{2}x_{3},x_{3}x_{1},x_{3}x_{2},x_{3}x_{3})$$用普通方法计算$$< f\left( x \right),f\left( y \right) >$$步骤为：$$x = \left( x_{1},x_{2},x_{3} \right);y = \left( y_{1},y_{2},y_{3} \right);$$$$f\left( x \right) = (x_{1}x_{1},x_{1}x_{2},x_{1}x_{3},x_{2}x_{1},x_{2}x_{2},x_{2}x_{3},x_{3}x_{1},x_{3}x_{2},x_{3}x_{3})$$$$f\left( y \right) = \left( y_{1}y_{1},y_{1}y_{2},y_{1}y_{3},y_{2}y_{1},y_{2}y_{2},y_{2}y_{3},y_{3}y_{1},y_{3}y_{2},y_{3}y_{3} \right)$$$$< f\left( x \right),f\left( y \right) > = \left( x_{1}y_{1} \right)^{2} + \left( x_{2}y_{2} \right)^{2} + \left( x_{3}y_{3} \right)^{2} + 2\left( x_{1}x_{2}y_{1}y_{2} + x_{1}x_{3}y_{1}y_{3} + x_{2}x_{3}y_{2}y_{3} \right)$$而通过核函数，我们能够发现：$$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  < f\left( x \right),f\left( y \right) >$$$$= \left( x_{1}y_{1} + x_{2}y_{2} + x_{3}y_{3} \right)^{2} = \left( < x,y > \right)^{2}$$这样就避免了多维的复杂计算，降低了算法复杂度。3.1 算法描述------------3.2 算法分析及优化------------------线性支持向量机在对一个新的实例进行分类时时间复杂度为 $$O\left( s\right)$$ ，其中s为非零特征的数量，这个时间复杂度与其它线性分类器是相同的，比如上一个方法朴素贝叶斯。但是训练出一个SVM的时间复杂度为 $$O\left(n^{2} \right)$$ ，其中n为训练案例数量。### Online SVM:在传统的方式中，支持向量机通常采取批处理模式，这是指学习一批固定的训练数据集，然后应用在独立的案例中。而针对邮件分类这种增长式的数据，我们需要对把传统的批处理模式升级为线上处理模式(OnlineSVM)，因为邮件是源源不断的，也是需要不断优化的。我们需要让模型在接收每一个案例之后，都会被告知分类正确与否，并对旧的SVM做出调整和更新。### Relaxed Online SVM(ROSVM)在训练SVM时，我们需要满足如下条件：要使下面的函数最小:$$\tau\left( w,\varepsilon \right) = \frac{1}{2}\left| \left| w \right| \right|^{2} + C\sum_{i = 1}^{n}\varepsilon_{i}$$同时满足限制$$for\ all\ i = 1..n:y_{i}\left( < w,x_{i} > + b \right) \geq 1 - \varepsilon_{i},\varepsilon_{i} \geq 0$$其中 $$\varepsilon_{i}$$ 表示的是对于特定的例子$$x_{i}$$分类器分类错误的数量。使得 $$\sum_{i= 1}^{n}\varepsilon_{i}$$ 最小等价于使得损失函数最小，而使得$$\left| \left| w\right|\right|^{2}$$最小意味着使得两类的距离最大。这两种最优解的寻找通常是冲突的，其中C(tradeoffparameter)就反映了对这两种查找的重要性的分配。通过实验，学者发现把C设置为较高的值会得到更高的准确性。把C设置为较高的值意味着达到训练损失最小比实现最大距离要更重要。这就提醒我们，训练过程中注重找到对于所有数据实现最大距离是不必要的，我们就需要对这个需求放宽标准(relax)。有这样几种方式实现放宽标准：1. 对于该寻找最优问题，将范围限制在最近的p个实例中，而非所有实例。2. 通过只对错误作出反应，减少对模型更新的次数。3. 通过允许用近似解取代最优解，减少迭代的次数。<h1 id="4">    4N元语法模型(n-gram language model)</h1><h2 id="4-0-引入"><a href="#4-0-引入" class="headerlink" title="4.0 引入"></a>4.0 引入</h2><p>由于现在的垃圾邮件有的会为了躲避词频或特定词的侦查，会选择插入一些特殊符号将词汇变形，而仍然让人能看懂，比如”free”->”f*r*e*e”。这种伎俩有时候能欺骗分词工具，使我们提取不到有效词汇。而且对于语法丰富的自然语言，尤其是词形多变的语种，很少有分词工具能够完全将其拆分的。同时，建立词袋只统计词频，而忽视了词出现的顺序，这样会丢失部分信息。</p><h2 id="4-1-算法原理"><a href="#4-1-算法原理" class="headerlink" title="4.1 算法原理"></a>4.1 算法原理</h2><p>如果我们想要计算<script type="math/tex">P\left( w \middle| h\right)</script>，其中w为一个词，h为在它之前的历史文本。那么我们需要一个很大的语料库（比如网络）来统计。比如计算<script type="math/tex">P\left(土豆|我们都爱吃 \right) = \frac{C\left(我们都爱吃土豆\right)}{C(我们都爱吃)}</script>其中C表示（count）次数。但是这种方法从复杂性上、实用性上都不够现实，因此我们需要选择更聪明的方法。</p><p>通过链式法则，我们可以将上述概率分解为</p><script type="math/tex; mode=display">P\left( 我们都爱吃土豆\right) = P\left( 我们\right)P\left( 都\middle| 我们\right)P\left( 爱\middle| 我们都\right)P\left(吃 \middle|我们都爱 \right)P\left(土豆 \middle|我们都爱吃 \right)</script><p>定义记号<script type="math/tex">w_{a}^{b}</script>表示由a到b这b-a+1个词组成的序列，则链式法则用字母表示为</p><script type="math/tex; mode=display">P\left( w_{1}^{n} \right) = P\left( w_{1} \right)P\left( w_{2} \middle| w_{1} \right)P\left( w_{3} \middle| w_{1}^{2} \right)\ldots P\left( w_{n} \middle| w_{1}^{n - 1} \right)</script><script type="math/tex; mode=display">= \Pi_{k = 1}^{n}P\left( w_{k} \middle| w_{1}^{k - 1} \right)</script><p>N-gram模型的逻辑在于，我们可以用最后几个单词来估计历史h，而不需要查看整个历史中的概率。方程为</p><script type="math/tex; mode=display">P\left( w_{n} \middle| w_{1}^{n - 1} \right) \approx P\left( w_{n} \middle| w_{n - N + 1}^{n - 1} \right)</script><p>如果引入马尔科夫假设，即单词的概率只取决于前一个词，那么N-gram特定为bigram(N=2)。可以将联合概率写作</p><script type="math/tex; mode=display">P\left( w_{1}^{n} \right) = \prod_{k = 1}^{n}{P\left( w_{k} \middle| w_{k - 1} \right)}</script><h2 id="4-2-实现思路"><a href="#4-2-实现思路" class="headerlink" title="4.2 实现思路"></a>4.2 实现思路</h2><p>采用训练集，分别训练出两个分类spam/ham的模型。对于新的测试邮件，分别通过两个模型得到的概率去预测它，看哪个模型预测得更接近，就将其归为哪一类。此过程可以衍生出很多方法，比如分词方式有词组、字符等，判断方式也可以只依靠邮件的前几个词。</p><p>有人采用了字符为单位的学习方式。这表示对文本进行划分的单元不是单词，而是几个字符，比如将discount分为3个字母一组，这样就算被插入了一些扰乱的字符，比如di<em>scount，在这种分词模式下分成di</em>|sco|oun|t，与discount的大部分小模块还是相同的。</p><h2 id="4-3算法分析"><a href="#4-3算法分析" class="headerlink" title="4.3算法分析"></a>4.3算法分析</h2><h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><p>包含了前N-1个词能提供的全部信息，并且原理简单容易实现。</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>首先，这种方法需要大量的训练数据来确定模型的参数。</p><p>还有，因为数据稀疏会导致出现数据平滑问题。比如很多词汇组合的概率为0，这时就需要优化算法。</p><h1 id="2333">    参考文献</h1><ol><li><p>Naïve Bayes: <a href="https://scikit-learn.org/stable/modules/naive_bayes.html" target="_blank" rel="noopener">https://scikit-learn.org/stable/modules/naive_bayes.html</a></p></li><li><p>SVM：《统计学习方法》，李航 著。</p></li><li><p>”Relaxed Online SVMs for Spam Filtering”:<br><a href="https://www.eecs.tufts.edu/~dsculley/papers/emailAndWebSpamSIGIR.pdf" target="_blank" rel="noopener">https://www.eecs.tufts.edu/~dsculley/papers/emailAndWebSpamSIGIR.pdf</a></p></li><li><p>n元语法模型：<a href="https://web.stanford.edu/~juraf" target="_blank" rel="noopener">https://web.stanford.edu/~juraf</a></p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/06/15/hello-world/"/>
    <url>/2020/06/15/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><div class="hljs"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre></div><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><div class="hljs"><pre><code class="hljs bash">$ hexo server</code></pre></div><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><div class="hljs"><pre><code class="hljs bash">$ hexo generate</code></pre></div><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><div class="hljs"><pre><code class="hljs bash">$ hexo deploy</code></pre></div><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
